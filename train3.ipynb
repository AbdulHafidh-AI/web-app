{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eaed17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d4e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc5d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11ccdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d140e869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdulhafidh/Documents/exam/exam-venv/lib/python3.9/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.7237 - sparse_categorical_accuracy: 0.7990 - val_loss: 0.2380 - val_sparse_categorical_accuracy: 0.9317\n",
      "Epoch 2/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9363 - val_loss: 0.1810 - val_sparse_categorical_accuracy: 0.9503\n",
      "Epoch 3/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - loss: 0.1685 - sparse_categorical_accuracy: 0.9516 - val_loss: 0.1502 - val_sparse_categorical_accuracy: 0.9575\n",
      "Epoch 4/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - loss: 0.1366 - sparse_categorical_accuracy: 0.9605 - val_loss: 0.1291 - val_sparse_categorical_accuracy: 0.9620\n",
      "Epoch 5/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 0.1174 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1152 - val_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 6/6\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.0993 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.1059 - val_sparse_categorical_accuracy: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x177bd8310>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001), # optimization function\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), # loss function\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=6,\n",
    "    validation_data=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ca6a354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 - 0s - 513us/step - loss: 0.1059 - sparse_categorical_accuracy: 0.9679\n",
      "\n",
      "Test accuracy: 0.9678999781608582\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "test_loss, test_acc = model.evaluate(ds_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09b112cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find a sample of digit 2 in the test set\n",
    "for image, label in ds_test.unbatch():\n",
    "    number = 3\n",
    "    if label.numpy() == number:\n",
    "        plt.imshow(image.numpy().reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"Sample of digit {number}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "572d6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into h5 format\n",
    "model.save('mnist_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exam-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
